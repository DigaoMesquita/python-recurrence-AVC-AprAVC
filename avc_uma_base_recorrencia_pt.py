# -*- coding: utf-8 -*-
"""AVC_uma_base_recorrencia_pt.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f5kJWfcMjr7BpclHJ2sMV22ABb0S9PJ-

# **Modelo de previsão de AVC.**

# **Bibliotecas e CSV**

Instalando algumas bibliotecas que não são default do COLAB
"""

!pip install catboost

"""Importando as blibliotecas"""

import pandas as pd
import numpy as np
import time
from numpy import mean
from numpy import std
import matplotlib.pyplot as plt
import seaborn as sns
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import TomekLinks, RandomUnderSampler, NearMiss, OneSidedSelection
from sklearn import metrics
from sklearn.datasets import make_classification
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold, train_test_split
from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score,ConfusionMatrixDisplay,precision_score,recall_score,r2_score,f1_score,classification_report,roc_curve,auc,precision_recall_curve,average_precision_score
#from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score,ConfusionMatrixDisplay,precision_score,recall_score,r2_score,f1_score,classification_report,roc_curve,auc,precision_recall_curve,plot_precision_recall_curve,average_precision_score
#from sklearn.metrics import plot_confusion_matrix, plot_roc_curve
#from sklearn.metrics import plot_roc_curve
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier

"""Lendo o CSV"""

#data=pd.read_csv('cruz-bs_liga-bs_amer_trei.csv')
#data=pd.read_csv('mods-h20.csv')
#data=pd.read_csv('base-americana-treino-train_ig_0_e_1.csv')
#data=pd.read_csv('base_americana-healthcare-stroke_ig_0_e_1.csv')
#data=pd.read_csv('base_americana-healthcare-stroke_ig_num.csv')
data=pd.read_csv('base_cruzada_liga_hgf_popularCSVpt.csv')

#O ID nada mais é do que um número único atribuído a cada paciente para controlá-los e torná-los únicos.
#Não há necessidade de ID, é totalmente inútil, então vamos removê-lo.
data.drop("id",inplace=True,axis=1)

len(data)

data.head()

data.sample(10)

data.columns

data.values

unique_counts = pd.DataFrame.from_records([(col, data[col].nunique()) for col in data.columns],
                          columns=['Column_Name', 'Num_Unique']).sort_values(by=['Num_Unique'])

unique_counts

"""# **EDA**


A análise exploratória de dados (EDA) é uma ferramenta poderosa e simples que pode ser usada para melhorar sua compreensão de seus dados, explorando suas propriedades. A técnica é frequentemente aplicada quando o objetivo é criar novas hipóteses ou encontrar padrões nos dados. É frequentemente usado em grandes quantidades de dados qualitativos ou quantitativos que não foram analisados ​​antes. É uma das tecnicas da engenharia de recursos.

**Sexo**

Este atributo indica o sexo do paciente. Vamos ver como o gênero afeta e uma comparação inteligente da taxa de AVC.
"""

print('Unique values\n',data['sexo'].unique())
print('Value Counts\n',data['sexo'].value_counts())
# Os códigos acima nos ajudarão a nos fornecer informações sobre seus valores exclusivos e a contagem de cada valor.
sns.countplot(data=data,x='sexo',color='gray')
# Ajuda a traçar um gráfico de contagem que nos ajudará a ver a contagem de valores em cada categoria única.
sns.countplot(data=data,x='sexo',hue='avc2')
# Este gráfico ajudará a analisar como o gênero afetará as chances do 2° acidente vascular cerebral.

"""**Idade**

Bem, aqui a idade não é apenas um número, é um dos significantes ou, como podemos dizer, é um fator muito importante. Vamos analisar nossos dados e ver quanto impacto tem o impacto real.
"""

data['idade'].nunique()
# Retorna o número de valores únicos neste atributo
sns.displot(data['idade'])
# Isso representará um gráfico de distribuição de idade variável
plt.figure(figsize=(15,7))
sns.boxplot(data=data,x='avc2',y='idade')
# O código acima representará um gráfico de caixa de idade variável em relação ao traço do atributo alvo

"""Número de valores únicos:

**Hipertensão**

A hipertensão é uma condição em que uma pessoa tem pressão alta. A hipertensão pode resultar em um acidente vascular cerebral. Vamos ver como acontece.
"""

data['idade'].nunique()
# Retorna o número de valores únicos neste atributo
sns.displot(data['idade'])
# Isso representará um gráfico de distribuição de idade variável
plt.figure(figsize=(15,7))
sns.boxplot(data=data,x='avc2',y='idade')
# O código acima representará um gráfico de caixa de idade variável em relação ao traço do atributo alvo

print('Unique Value\n',data['hipertensao'].unique())
print('Value Counts\n',data['hipertensao'].value_counts())
# O código acima retornará um valor único para o atributo de doença cardíaca e suas contagens de valor

sns.countplot(data=data,x='hipertensao',color='gray')
sns.countplot(data=data,x='hipertensao',hue='avc2')

"""**Doença cardíaca**

Pessoas com doenças cardíacas tendem a ter um risco maior de sofrer um derrame se os cuidados adequados não forem tomados.
"""

print('Unique Value\n',data['cardiaco'].unique())
print('Value Counts\n',data['cardiaco'].value_counts())
# O código acima retornará um valor único para o atributo de doença cardíaca e suas contagens de valor

sns.countplot(data=data,x='cardiaco', color='gray')
sns.countplot(data=data,x='cardiaco',hue='avc2')
#Representará um gráfico de contador de doenças cardíacas variáveis

"""**Já casado**

Esse atributo nos dirá se o paciente já foi casado ou não. Vamos ver como isso afetará as chances de ter um derrame.
"""

print('Unique Values\n',data['estado_civil'].unique())
print('Value Counts\n',data['estado_civil'].value_counts())
# O código acima nos mostrará valores únicos de número de atributo e sua contagem sns.countplot (data = data, x = 'ever_married')
sns.countplot(data=data,x='estado_civil',color='gray')
# Trama contrária do atributo já casado
sns.countplot(data=data,x='estado_civil',hue='avc2')
# Já casado com respeito ao 2° AVC

"""**Tipo de trabalho**

Este atributo contém dados sobre o tipo de trabalho que o paciente realiza. Diferentes tipos de trabalho têm diferentes tipos de problemas e desafios que podem ser a possível razão para excitação, emoção, estresse, etc. O estresse nunca é bom para a saúde, vamos ver como essa variável pode afetar as chances de ter um derrame.
"""

print('Unique Value\n',data['tipo_trabalho'].unique())
print('Value Counts\n',data['tipo_trabalho'].value_counts())
# O código acima retornará valores únicos de atributos e sua contagem
sns.countplot(data=data,x='tipo_trabalho', color='gray')
# O código acima irá criar um gráfico de contagem
sns.countplot(data=data,x='tipo_trabalho',hue='avc2')
# O código acima criará um gráfico de contagem em relação ao traço

"""**Tipo de Residência**

Este atributo nos diz se em que tipo de residência o paciente está. Pode ser Urbano ou Rural.
"""

print('Unique Values\n',data['tipo_residencia'].unique())
print("Value Counts\n",data['tipo_residencia'].value_counts())
# O código acima retornará valores únicos da variável e sua contagem
sns.countplot(data=data,x='tipo_residencia',color='gray')
# Isso criará um gráfico de contador
sns.countplot(data=data,x='tipo_residencia',hue='avc2')
# Tipo de residência em relação ao 2° AVC

"""**Diabetes**

Informa se o paciente possui diabetes
"""

print('Unique Value\n',data['diabetes'].unique())
print('Value Counts\n',data['diabetes'].value_counts())
# O código acima retornará um valor único para o atributo de diabetes e suas contagens de valor
sns.countplot(data=data,x='diabetes',color='gray')
sns.countplot(data=data,x='diabetes',hue='avc2')
#Avg_glucose_level e 2° AVC

"""**IMC**

O Índice de Massa Corporal é uma medida de gordura corporal baseada na altura e no peso que se aplica a homens e mulheres adultos. Vamos ver como isso afeta as chances de ter um derrame.
"""

# Retorna um número de valores nulos
data['imc'].isna().sum()
# Preenchendo valores nulos com valor médio
data['imc'].fillna(data['imc'].mean(),inplace=True)
# Retorna o número de valores únicos nesse atributo
data['imc'].nunique()
# Distribuição de imc
sns.displot(data['imc'])
# IMC em relação ao 2° AVC
plt.figure(figsize=(10,7))
sns.boxplot(data=data,x='avc2',y='imc',)

"""**Condição de fumante**

Esses atributos nos dizem se o paciente fuma ou não. Fumar é prejudicial à saúde e pode causar doenças cardíacas. Vamos ver como fica no caso de nossos dados.
"""

print('Unique Values\n',data['status_fumo'].unique())
print('Value Counts\n',data['status_fumo'].value_counts())
# Retorna valores únicos e sua contagem
sns.countplot(data=data,x='status_fumo',color='gray')
# Gráfico de contagem do status de fumante
sns.countplot(data=data,x='status_fumo',hue='avc2')
# Status de fumante em relação ao 2° AVC

"""**Condição de etilista**

Esses atributos nos dizem se o paciente bebe ou não.
"""

print('Unique Values\n',data['status_alcool'].unique())
print('Value Counts\n',data['status_alcool'].value_counts())
# Retorna valores únicos e sua contagem
sns.countplot(data=data,x='status_alcool',color='gray')
# Gráfico de contagem do status de etilista
sns.countplot(data=data,x='status_alcool',hue='avc2')
# Status de etilista em relação ao 2° AVC

"""**Condição de depressão/ansiedade**

Esses atributos nos dizem se o paciente tem depressão/ansiedade.
"""

print('Unique Values\n',data['depressao_ansiedade'].unique())
print('Value Counts\n',data['depressao_ansiedade'].value_counts())
# Retorna valores únicos e sua contagem
sns.countplot(data=data,x='depressao_ansiedade',color='gray')
# Gráfico de contagem do status de depressão_ansiedade
sns.countplot(data=data,x='depressao_ansiedade',hue='avc2')
# Status de depressão_ansiedade em relação ao 2° AVC

"""**Primeiro evento do AVC**

Pessoas que tiveram o primeiro evento tendem a ter um risco maior de sofrer um segundo derrame se os cuidados adequados não forem tomados.
"""

print('Unique Value\n',data['avc1'].unique())
print('Value Counts\n',data['avc1'].value_counts())
# O código acima retornará um valor único para o atributo do 1° AVC e suas contagens de valor

sns.countplot(data=data,x='avc1', color='gray')
sns.countplot(data=data,x='avc1',hue='avc2')
#Representará um gráfico de contador do 1° AVC

"""**Recorrencia do AVC**

Nossa variável de destino. Ela nos diz se os pacientes têm chances de ter  derrame pela segunda vez.
"""

print('Unique Value\n',data['avc2'].unique())
print('Value Counts\n',data['avc2'].value_counts())
# Retorna o valor único e sua contagem
sns.countplot(data=data,x='avc2')
# Plotagem de contagem do 2° AVC

"""# **Engenharia de Recursos**

**Codificação de rótulo**

Nosso conjunto de dados é uma mistura de dados categóricos e numéricos e, como os algoritmos de ML entendem os dados de natureza numérica, vamos codificar nossos dados categóricos em numéricos usando o Label Encoder. Label Encoder é uma técnica que converte dados categóricos em dados numéricos. Ele pega o valor em ordem crescente e o converte em dados numéricos de 0 a n-1.
"""

cols=data.select_dtypes(include=['object']).columns
print(cols)
# Este código buscará colunas cujo tipo de dados é objeto.
le=LabelEncoder()
# Inicializando nosso objeto Label Encoder

data[cols]=data[cols].apply(le.fit_transform)
# Transferência de dados categóricos para numéricos
print(data.head(10))

#data = data.dropna()#excluir todas as linhas do dataset por N/A
data = data.fillna(0)#transforma todos os N/A no dataset em 0
#data = data.replace(np.nan,1)#transforma todos os N/A no dataset em 1 ou qualquer numero que desejar.

data.head

colunas = data.columns
colunas

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import KFold
from sklearn import preprocessing


x = data.values
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
data = pd.DataFrame(x_scaled)

data.columns = colunas

data.head(30)

"""**Correlação**"""

plt.figure(figsize=(15,10))
sns.heatmap(data.corr(),annot=True,fmt='.2')
plt.savefig('matriz_correlacao.png')

"""Observação: As variáveis ​​que mostram alguma correlação efetiva são: idade, hipertensão, doença cardíaca, estado civil, diabetes e fumante . Por segurança, vamos verificar nossos recursos usando SelectKBest e F_Classif."""

#classifier = SelectKBest(score_func=f_classif,k=5)
classifier = SelectKBest(score_func=f_classif,k=8)
fits = classifier.fit(data.drop('avc2',axis=1),data['avc2'])
x=pd.DataFrame(fits.scores_)
columns = pd.DataFrame(data.drop('avc2',axis=1).columns)
fscores = pd.concat([columns,x],axis=1)
fscores.columns = ['Attribute','Score']
fscores.sort_values(by='Score',ascending=False)

"""No resultado acima, podemos ver que a idade é uma variável altamente correlacionada e então fica decrescente. Estou mantendo a pontuação limite em 10. Resultando nos mesmos recursos que obtivemos no mapa de calor."""

cols=fscores[fscores['Score']>10]['Attribute']
print(cols)

"""# **Dividindo dados**

Agora, vamos dividir os recursos em conjuntos de treinamento e teste para treinar e testar nossos modelos de classificação.
"""

train_x,test_x,train_y,test_y=train_test_split(data[cols],data['avc2'],shuffle=True,random_state=8000,test_size=0.30)
# Dividindo dados
train_x.shape,test_x.shape,train_y.shape,test_y.shape

teste_x = test_x
teste_y = test_y

teste_x.shape,teste_y.shape

teste_x.head(14)

teste_y.head(14)

"""# **Conjunto de dados de balanceamento**

Como sabemos, nosso conjunto de dados está desequilibrado. Então, vamos equilibrar nossos dados. Vamos fazer o teste realizando uma técnica de undersampling, oversampling e as suas juntas.

**Técnicas de Undersampling**
"""

### Random Undersampler
rus = RandomUnderSampler(random_state=32)
##X_rus_res, y_rus_res = rus.fit_resample(X, y)
train_x,train_y = rus.fit_resample(train_x,train_y)
test_x,test_y = rus.fit_resample(test_x,test_y)

## NearMiss
nm=NearMiss(version=1)
##X_nm_res, y_nm_res = nm.fit_resample(X, y)
train_x,train_y = nm.fit_resample(train_x,train_y)
test_x,test_y = nm.fit_resample(test_x,test_y)


## OneSidedSelection (Algoritmo tipo KNN)
oss = OneSidedSelection(random_state=32)
##X_oss_res, y_oss_res = oss.fit_resample(X, y)
train_x,train_y = oss.fit_resample(train_x,train_y)
test_x,test_y = oss.fit_resample(test_x,test_y)

train_x.shape,test_x.shape,train_y.shape,test_y.shape

"""**Técnica de Oversampling**

Vamos usar o método SMOTE (Synthetic Minority Oversampling Technique) é uma técnica estatística para aumentar o número de casos em seu conjunto de dados de maneira equilibrada. O componente funciona gerando novas instâncias de casos minoritários existentes que você fornece como entrada.

Normalmente, fazemos isso em todo o conjunto de dados, mas como temos muito menos registros de classes secundárias, estou aplicando nos dados de treino e de teste.

Anteriormente, tentei fazer isso apenas reamostrando os dados do conjunto de dados de treinamento, mas não funcionou muito bem, então tentei essa abordagem e obtive um bom resultado.
"""

## Smote

smote=SMOTE()
train_x,train_y=smote.fit_resample(train_x,train_y)
test_x,test_y=smote.fit_resample(test_x,test_y)

train_x.shape,test_x.shape,train_y.shape,test_y.shape

"""# **Criação de Modelo**

Função para a definição da Curva de ROC
"""

def plot_roc_curve(fper, tper):
    plt.plot(fper, tper, color='red', label='ROC')
    plt.plot([0, 1], [0, 1], color='green', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC - Receiver Operating Characteristic Curve', fontsize = 14)
    plt.legend()
    plt.show()

"""Função para definição dos resultados por validação cruzada, com o resultado de cada métrica para cada fold, a média por métrica e o desvio padrão por métrica. Metricas: AUC_ROC, F1 Score, Precisão, Recall, Acuracia.


"""

def cross(results,mscr):

    media = np.mean(results)
    dv = np.std(results)

    if(mscr=="ROC_AUC"):
      print("Valor do", mscr, "para cada fold: {}".format(results))
      print("Média", mscr, "{:.2f}".format(media))
      print("Devio Padrão para" , mscr, ": {:.4f}".format(dv))
      print("\n")
    else:
      print("Valor do", mscr, "para cada fold: {}".format(results))
      print("Média", mscr, "{:.2f}%".format(media*100))
      print("Devio Padrão para" , mscr, ": {:.4f}".format(dv))
      print("\n")

"""**Decision Tree Classifier**"""

print('DECISION TREE CLASSIFIER')

dtc=DecisionTreeClassifier(criterion='entropy',max_depth=20)
print('\n')

print('========================')
print('VALIDAÇÃO CRUZADA')
print('========================')
print('\n')

startdtc_cv = time.time()
for score in ["accuracy", "precision", "recall", "f1", "roc_auc"]:
#  print(score)
  scr = score
  mscr = scr.upper()
#  print(Mscr)
  cv = StratifiedKFold(n_splits = 5, shuffle = True)
  results = cross_val_score(dtc, train_x, train_y, cv = 5, scoring=score)
  cross(results,mscr)
#std_dtc = np.std(results)
#mean_dtc = np.mean(results)
#print("Acurácias para cada fold: {}".format(results))
#print('Média AUC-ROC:', mean_dtc)
#print("Desvio padrão da acurácia: {:.2f}".format(std_dtc))
#intervalo(results)
enddtc_cv = time.time()
print('Tempo de processamento do modelo para a validação cruzada:', enddtc_cv-startdtc_cv)
print('\n')

print('========================')
print('MODELO REAL')
print('========================')
print('\n')

startdtc = time.time()
dtc.fit(train_x,train_y)
predict_dtc=dtc.predict(test_x)
predict_prob_dtc = dtc.predict_proba(test_x)[:,1]

cm_dtc = confusion_matrix(test_y, predict_dtc)
heatmap = sns.heatmap(cm_dtc, annot=True, fmt='d')
heatmap.set_title('Matriz de Confusão')
heatmap.set_xlabel('Classe Predita')
heatmap.set_ylabel('Classe Verdadeira')
plt.show()

#cm_dtc = confusion_matrix(test_y, predict_dtc, labels=dtc.classes_)
#disp_dtc = ConfusionMatrixDisplay(confusion_matrix=cm_dtc,display_labels=dtc.classes_)
#disp_dtc.plot()
#plt.show()

fper_dtc, tper_dtc, thresholds = roc_curve(test_y, predict_prob_dtc)

print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_dtc)*100))
#print('Accuracy --> ',accuracy_score(test_y,predict_dtc))

print('Precision --> {:.4}%' .format(precision_score(test_y,predict_dtc)*100))
##print('Recall --> ',recall_score(y_test,predict_dtc))

print('Recall --> {:.4}%' .format(recall_score(test_y,predict_dtc)*100))
##print('Recall --> ',recall_score(y_test,predict_dtc))

print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_dtc)*100))
##print('F1 Score --> ',f1_score(test_y,predict_dtc))

print('Classification Report  --> \n',classification_report(test_y,predict_dtc))

plot_roc_curve(fper_dtc, tper_dtc)
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_dtc)))

#desvio_padrao = np.std(test_y - predict_dtc)
#print(desvio_padrao)

#desvio_padrao1 = np.std(test_y)
#print(desvio_padrao1)

enddtc = time.time()
print('Tempo de processamento do modelo:', enddtc-startdtc)
print('\n')

print('========================')
print('TESTANDO O MODELO')
print('========================')
print('\n')

print("Amostra selecionada:\n", teste_x[50:51])
print("Resultado da amostra selecionada:\n", teste_y[50:51])

previsoesdoalgoritmoDTC=dtc.predict(teste_x[50:51])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoDTC)


print("Amostra selecionada:\n", teste_x[13:14])
print("Resultado da amostra selecionada:\n", teste_y[13:14])

previsoesdoalgoritmoDTC=dtc.predict(teste_x[13:14])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoDTC)

"""**KNN**"""

print('KNN')

knn = KNeighborsClassifier(n_neighbors=30) # P/ undersampling e oversampling
#knn = KNeighborsClassifier(n_neighbors=100) #aplicar apenas para oversampling
print('\n')

print('========================')
print('VALIDAÇÃO CRUZADA')
print('========================')
print('\n')

startknn_cv = time.time()
#SEED = 42
#np.random.seed(SEED)
for score in ["accuracy", "precision", "recall", "f1", "roc_auc"]:
  scr = score
  mscr = scr.upper()
  cv = StratifiedKFold(n_splits = 5, shuffle = True)
  results = cross_val_score(knn, train_x, train_y, cv = 5, scoring=score)
  cross(results,mscr)
endknn_cv = time.time()
print('Tempo de processamento do modelo para a validação cruzada:', endknn_cv-startknn_cv)
print('\n')

print('========================')
print('MODELO REAL')
print('========================')
print('\n')

startknn = time.time()
knn.fit(train_x,train_y)
predict_knn=knn.predict(test_x)
predict_prob_knn = knn.predict_proba(test_x)[:,1]

cm_knn = confusion_matrix(test_y, predict_knn)
heatmap = sns.heatmap(cm_knn, annot=True, fmt='d')
heatmap.set_title('Matriz de Confusão')
heatmap.set_xlabel('Classe Predita')
heatmap.set_ylabel('Classe Verdadeira')
plt.show()

#cm_knn = confusion_matrix(test_y, predict_knn, labels=knn.classes_)
#disp_knn = ConfusionMatrixDisplay(confusion_matrix=cm_knn,display_labels=knn.classes_)
#disp_knn.plot()
#plt.show()

fper_knn, tper_knn, thresholds = roc_curve(test_y, predict_prob_knn)

print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_knn)*100))

print('Precision --> {:.4}%' .format(precision_score(test_y,predict_knn)*100))

print('Recall --> {:.4}%' .format(recall_score(test_y,predict_knn)*100))

print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_knn)*100))

print('Classification Report  --> \n',classification_report(test_y,predict_knn))

plot_roc_curve(fper_knn, tper_knn)
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_knn)))

endknn = time.time()
print('Tempo de processamento do modelo:', endknn-startknn)
print('\n')

print('========================')
print('TESTANDO O MODELO')
print('========================')
print('\n')

print("Amostra selecionada:\n", teste_x[50:51])
print("Resultado da amostra selecionada:\n", teste_y[50:51])

previsoesdoalgoritmoKNN=knn.predict(teste_x[50:51])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoKNN)

print("Amostra selecionada:\n", teste_x[13:14])
print("Resultado da amostra selecionada:\n", teste_y[13:14])

previsoesdoalgoritmoKNN=knn.predict(teste_x[13:14])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoKNN)

"""**Logistic Regression**"""

print('LOGISTIC REGRESSION')

#lor=LogisticRegression()
#lor=LogisticRegression(random_state=0,C=100000,n_jobs=-1)
#lor=LogisticRegression(random_state=0,C=1000,n_jobs=-1)
lor=LogisticRegression(random_state=1,C=500)
print('\n')

print('========================')
print('VALIDAÇÃO CRUZADA')
print('========================')
print('\n')

startlor_cv = time.time()
#SEED = 42
#np.random.seed(SEED)
for score in ["accuracy", "precision", "recall", "f1", "roc_auc"]:
  scr = score
  mscr = scr.upper()
  cv = StratifiedKFold(n_splits = 5, shuffle = True)
  results = cross_val_score(lor, train_x, train_y, cv = 5, scoring=score)
  cross(results,mscr)
endlor_cv = time.time()
print('Tempo de processamento do modelo para a validação cruzada:', endlor_cv-startlor_cv)
print('\n')


print('========================')
print('MODELO REAL')
print('========================')
print('\n')

startlor = time.time()
lor.fit(train_x,train_y)
predict_lor=lor.predict(test_x)
predict_prob_lor = lor.predict_proba(test_x)[:,1]

cm_lor = confusion_matrix(test_y, predict_lor)
heatmap = sns.heatmap(cm_lor, annot=True, fmt='d')
heatmap.set_title('Matriz de Confusão')
heatmap.set_xlabel('Classe Predita')
heatmap.set_ylabel('Classe Verdadeira')
plt.show()

#cm_lor = confusion_matrix(test_y, predict_lor, labels=lor.classes_)
#disp_lor = ConfusionMatrixDisplay(confusion_matrix=cm_lor,display_labels=lor.classes_)
#disp_lor.plot()
#plt.show()

fper_lor, tper_lor, thresholds = roc_curve(test_y, predict_prob_lor)

print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_lor)*100))
#print('Accuracy --> ',accuracy_score(test_y,predict_lor))

print('Precision --> {:.4}%' .format(precision_score(test_y,predict_lor)*100))

print('Recall --> {:.4}%' .format(recall_score(test_y,predict_lor)*100))
##print('Recall --> ',recall_score(y_test,predict_lor))

print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_lor)*100))
#print('F1 Score --> ',f1_score(test_y,predict_lor))

print('Classification Report  --> \n',classification_report(test_y,predict_lor))

plot_roc_curve(fper_lor, tper_lor)
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_lor)))

endlor = time.time()
print('Tempo de processamento do modelo:', endlor-startlor)
print('\n')

print('========================')
print('TESTANDO O MODELO')
print('========================')
print('\n')

print("Amostra selecionada:\n", teste_x[50:51])
print("Resultado da amostra selecionada:\n", teste_y[50:51])

previsoesdoalgoritmoLOR=lor.predict(teste_x[50:51])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoLOR)

print("Amostra selecionada:\n", teste_x[13:14])
print("Resultado da amostra selecionada:\n", teste_y[13:14])

previsoesdoalgoritmoLOR=lor.predict(teste_x[13:14])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoLOR)

"""**Naive Bayes**"""

print('NAIVE BAYES')

gnb=GaussianNB()
print('\n')

print('========================')
print('VALIDAÇÃO CRUZADA')
print('========================')
print('\n')

startgnb_cv = time.time()
#SEED = 42
#np.random.seed(SEED)
for score in ["accuracy", "precision", "recall", "f1", "roc_auc"]:
  scr = score
  mscr = scr.upper()
  cv = StratifiedKFold(n_splits = 5, shuffle = True)
  results = cross_val_score(gnb, train_x, train_y, cv = 5, scoring=score)
  cross(results,mscr)
endgnb_cv = time.time()
print('Tempo de processamento do modelo para a validação cruzada:', endgnb_cv-startgnb_cv)
print('\n')

print('========================')
print('MODELO REAL')
print('========================')
print('\n')

startgnb = time.time()
gnb.fit(train_x,train_y)
predict_gnb=gnb.predict(test_x)
predict_prob_gnb = gnb.predict_proba(test_x)[:,1]

cm_gnb = confusion_matrix(test_y, predict_gnb)
heatmap = sns.heatmap(cm_gnb, annot=True, fmt='d')
heatmap.set_title('Matriz de Confusão')
heatmap.set_xlabel('Classe Predita')
heatmap.set_ylabel('Classe Verdadeira')
plt.show()

#cm_gnb = confusion_matrix(test_y, predict_gnb, labels=gnb.classes_)
#disp_gnb = ConfusionMatrixDisplay(confusion_matrix=cm_gnb,display_labels=gnb.classes_)
#disp_gnb.plot()
#plt.show()

fper_gnb, tper_gnb, thresholds = roc_curve(test_y, predict_prob_gnb)

print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_gnb)*100))

print('Precision --> {:.4}%' .format(precision_score(test_y,predict_gnb)*100))

print('Recall --> {:.4}%' .format(recall_score(test_y,predict_gnb)*100))

print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_gnb)*100))

print('Classification Report  --> \n',classification_report(test_y,predict_gnb))

plot_roc_curve(fper_gnb, tper_gnb)
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_gnb)))

endgnb = time.time()
print('Tempo de processamento do modelo:', endgnb-startgnb)
print('\n')

print('========================')
print('========================')
print('Testando o modelo')

print("Amostra selecionada:\n", teste_x[50:51])
print("Resultado da amostra selecionada:\n", teste_y[50:51])

previsoesdoalgoritmoGNB=gnb.predict(teste_x[50:51])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoGNB)

print("Amostra selecionada:\n", teste_x[13:14])
print("Resultado da amostra selecionada:\n", teste_y[13:14])

previsoesdoalgoritmoGNB=gnb.predict(teste_x[13:14])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoGNB)

"""**SVM**"""

print('SVM')

#startsvc = time.time()
#svc=SVC(probability=True)
#svc=SVC(random_state=0,C=100000)
#svc=SVC(random_state=0,C=100)
svc=SVC(kernel='linear',C=1,probability=True)
print('\n')

print('========================')
print('VALIDAÇÃO CRUZADA')
print('========================')
print('\n')

startsvc_cv = time.time()
#SEED = 42
#np.random.seed(SEED)
for score in ["accuracy", "precision", "recall", "f1", "roc_auc"]:
  scr = score
  mscr = scr.upper()
  cv = StratifiedKFold(n_splits = 5, shuffle = True)
  results = cross_val_score(svc, train_x, train_y, cv = 5, scoring=score)
  cross(results,mscr)

endsvc_cv = time.time()
print('Tempo de processamento do modelo para a validação cruzada:', endsvc_cv-startsvc_cv)
print('\n')

print('========================')
print('MODELO REAL')
print('========================')
print('\n')

startsvc = time.time()
svc.fit(train_x,train_y)
predict_svc=svc.predict(test_x)
predict_prob_svc = svc.predict_proba(test_x)[:,1]

cm_svc = confusion_matrix(test_y, predict_svc)
heatmap = sns.heatmap(cm_svc, annot=True, fmt='d')
heatmap.set_title('Matriz de Confusão')
heatmap.set_xlabel('Classe Predita')
heatmap.set_ylabel('Classe Verdadeira')
plt.show()

#cm_svc = confusion_matrix(test_y, predict_svc, labels=svc.classes_)
#disp_svc = ConfusionMatrixDisplay(confusion_matrix=cm_svc,display_labels=svc.classes_)
#disp_svc.plot()
#plt.show()

fper_svc, tper_svc, thresholds = roc_curve(test_y, predict_prob_svc)

print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_svc)*100))
#print('Accuracy --> ',accuracy_score(predict_svc,test_y))

#print("Desvio Padrão: {:.2f}".format(np.std([accuracy_score(test_y,predict_svc)])))

print('Precision --> {:.4}%' .format(precision_score(test_y,predict_svc)*100))

print('Recall --> {:.4}%' .format(recall_score(test_y,predict_svc)*100))
##print('Recall --> ',recall_score(predict_dtc,test_y))

print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_svc)*100))
##print('F1 Score --> ',f1_score(predict_svc,test_y))

print('Classification Report  --> \n',classification_report(test_y,predict_svc))

plot_roc_curve(fper_svc, tper_svc)
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_svc)))

endsvc = time.time()
print('Tempo de processamento do modelo:', endsvc-startsvc)
print('\n')


print('========================')
print('========================')
print('Testando o modelo')


print("Amostra selecionada:\n", teste_x[50:51])
print("Resultado da amostra selecionada:\n", teste_y[50:51])

previsoesdoalgoritmoSVC=svc.predict(teste_x[50:51])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoSVC)

print("Amostra selecionada:\n", teste_x[13:14])
print("Resultado da amostra selecionada:\n", teste_y[13:14])

previsoesdoalgoritmoSVC=svc.predict(teste_x[13:14])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoSVC)

"""**Cat Boost Classifier**"""

print('CATBOOST CLASSIFIER')
#startcbc = time.time()
#cbc=CatBoostClassifier()
#cbc=CatBoostClassifier(verbose=0, n_estimators=1000)
cbc=CatBoostClassifier(verbose=0,n_estimators=2000,learning_rate=0.1)
print('\n')

print('========================')
print('VALIDAÇÃO CRUZADA')
print('========================')
print('\n')

startcbc_cv = time.time()
#SEED = 42
#np.random.seed(SEED)
for score in ["accuracy", "precision", "recall", "f1", "roc_auc"]:
  scr = score
  mscr = scr.upper()
  cv = StratifiedKFold(n_splits = 5, shuffle = True)
  results = cross_val_score(cbc, train_x, train_y, cv = 5, scoring=score)
  cross(results,mscr)

endcbc_cv = time.time()
print('Tempo de processamento do modelo para a validação cruzada:', endcbc_cv-startcbc_cv)
print('\n')

print('========================')
print('MODELO REAL')
print('========================')
print('\n')

startcbc = time.time()
cbc.fit(train_x,train_y)
predict_cbc=cbc.predict(test_x)
predict_prob_cbc = cbc.predict_proba(test_x)[:,1]

cm_cbc = confusion_matrix(test_y, predict_cbc)
heatmap = sns.heatmap(cm_cbc, annot=True, fmt='d')
heatmap.set_title('Matriz de Confusão')
heatmap.set_xlabel('Classe Predita')
heatmap.set_ylabel('Classe Verdadeira')
plt.show()

#cm_cbc = confusion_matrix(test_y, predict_cbc, labels=cbc.classes_)
#disp_cbc = ConfusionMatrixDisplay(confusion_matrix=cm_cbc,display_labels=cbc.classes_)
#disp_cbc.plot()
#plt.show()

fper_cbc, tper_cbc, thresholds = roc_curve(test_y, predict_prob_cbc)

print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_cbc)*100))
#print('Accuracy --> ',accuracy_score(test_y,predict_lgbmc))

#print("Desvio Padrão: {:.2f}".format(np.std([accuracy_score(test_y,predict_cbc)])))

print('Precision --> {:.4}%' .format(precision_score(test_y,predict_cbc)*100))

print('Recall --> {:.4}%' .format(recall_score(test_y,predict_cbc)*100))
##print('Recall --> ',recall_score(y_test,predict_lgbmc))

print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_cbc)*100))
##print('F1 Score --> ',f1_score(test_y,predict_lgbmc))

print('Classification Report  --> \n',classification_report(test_y,predict_cbc))

plot_roc_curve(fper_cbc, tper_cbc)
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_cbc)))
##print(f'ROC AUC score: {roc_auc_score(test_y,predict_prob_lgbmc)}')

endcbc = time.time()
print('Tempo de processamento do modelo:', endcbc-startcbc)
print('\n')


print('========================')
print('TESTANDO O MODELO')
print('========================')
print('\n')

print("Amostra selecionada:\n", teste_x[50:51])
print("Resultado da amostra selecionada:\n", teste_y[50:51])

previsoesdoalgoritmoCBC=cbc.predict(teste_x[50:51])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoCBC)

print("Amostra selecionada:\n", teste_x[13:14])
print("Resultado da amostra selecionada:\n", teste_y[13:14])

previsoesdoalgoritmoCBC=cbc.predict(teste_x[13:14])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoCBC)

"""**LGBMClassifier**"""

print('LGBM CLASSIFIER')

#startlgbmc = time.time()
#lgbmc=LGBMClassifier()
#lgbmc=LGBMClassifier(n_estimators=2000,max_depth=5)
lgbmc=LGBMClassifier(n_estimators=500,max_depth=50)
print('\n')

print('========================')
print('VALIDAÇÃO CRUZADA')
print('========================')
print('\n')

startlgbmc_cv = time.time()
#SEED = 42
#np.random.seed(SEED)
for score in ["accuracy", "precision", "recall", "f1", "roc_auc"]:
  scr = score
  mscr = scr.upper()
  cv = StratifiedKFold(n_splits = 5, shuffle = True)
  results = cross_val_score(lgbmc, train_x, train_y, cv = 5, scoring=score)
  cross(results,mscr)
endlgbmc_cv = time.time()
print('Tempo de processamento do modelo para a validação cruzada:', endlgbmc_cv-startlgbmc_cv)
print('\n')


print('========================')
print('MODELO REAL')
print('========================')
print('\n')

startlgbmc = time.time()
lgbmc.fit(train_x,train_y)
predict_lgbmc=lgbmc.predict(test_x)
predict_prob_lgbmc = lgbmc.predict_proba(test_x)[:,1]

cm_lgbmc = confusion_matrix(test_y, predict_lgbmc)
heatmap = sns.heatmap(cm_lgbmc, annot=True, fmt='d')
heatmap.set_title('Matriz de Confusão')
heatmap.set_xlabel('Classe Predita')
heatmap.set_ylabel('Classe Verdadeira')
plt.show()

#cm_lgbmc = confusion_matrix(test_y, predict_lgbmc, labels=lgbmc.classes_)
#disp_lgbmc = ConfusionMatrixDisplay(confusion_matrix=cm_lgbmc,display_labels=lgbmc.classes_)
#disp_lgbmc.plot()
#plt.show()

fper_lgbmc, tper_lgbmc, thresholds = roc_curve(test_y, predict_prob_lgbmc)

print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_lgbmc)*100))
#print('Accuracy --> ',accuracy_score(test_y,predict_lgbmc))

#print("Desvio Padrão: {:.2f}".format(np.std([accuracy_score(test_y,predict_lgbmc)])))

print('Precision --> {:.4}%' .format(precision_score(test_y,predict_lgbmc)*100))

print('Recall --> {:.4}%' .format(recall_score(test_y,predict_lgbmc)*100))
##print('Recall --> ',recall_score(y_test,predict_lgbmc))

print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_lgbmc)*100))
##print('F1 Score --> ',f1_score(test_y,predict_lgbmc))

print('Classification Report  --> \n',classification_report(test_y,predict_lgbmc))

plot_roc_curve(fper_lgbmc, tper_lgbmc)
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_lgbmc)))
##print(f'ROC AUC score: {roc_auc_score(test_y,predict_prob_lgbmc)}')

endlgbmc = time.time()
print('Tempo de processamento do modelo:', endlgbmc-startlgbmc)
print('\n')

print('========================')
print('TESTANDO O MODELO')
print('========================')
print('\n')

print("Amostra selecionada:\n", teste_x[50:51])
print("Resultado da amostra selecionada:\n", teste_y[50:51])

previsoesdoalgoritmoLGBMC=lgbmc.predict(teste_x[50:51])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoLGBMC)

print("Amostra selecionada:\n", teste_x[13:14])
print("Resultado da amostra selecionada:\n", teste_y[13:14])

previsoesdoalgoritmoLGBMC=lgbmc.predict(teste_x[13:14])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoLGBMC)

"""**Random** **Forest**"""

print('RANDOM FOREST')
#startrf = time.time()
#rf=RandomForestClassifier()
#rf=RandomForestClassifier(criterion='gini',max_depth=5,n_estimators=100000,n_jobs=-1)
#rf=RandomForestClassifier(criterion='gini',max_depth=5,n_estimators=1000,n_jobs=-1)
#rf=RandomForestClassifier(random_state=1)
rf=RandomForestClassifier(criterion='entropy',n_estimators=100,random_state=1)
print('\n')

print('========================')
print('VALIDAÇÃO CRUZADA')
print('========================')
print('\n')

startrf_cv = time.time()
#SEED = 42
#np.random.seed(SEED)
for score in ["accuracy", "precision", "recall", "f1", "roc_auc"]:
  scr = score
  mscr = scr.upper()
  cv = StratifiedKFold(n_splits = 5, shuffle = True)
  results = cross_val_score(rf, train_x, train_y, cv = 5, scoring=score)
  cross(results,mscr)
endrf_cv = time.time()
print('Tempo de processamento do modelo para a validação cruzada:', endrf_cv-startrf_cv)
print('\n')

print('========================')
print('MODELO REAL')
print('========================')
print('\n')

startrf = time.time()
rf.fit(train_x,train_y)
predict_rf=rf.predict(test_x)
predict_prob_rf = rf.predict_proba(test_x)[:,1]

cm_rf = confusion_matrix(test_y, predict_rf)
heatmap = sns.heatmap(cm_rf, annot=True, fmt='d')
heatmap.set_title('Matriz de Confusão')
heatmap.set_xlabel('Classe Predita')
heatmap.set_ylabel('Classe Verdadeira')
plt.show()

#cm_rf = confusion_matrix(test_y, predict_rf, labels=rf.classes_)
#disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf,display_labels=rf.classes_)
#disp_rf.plot()
#plt.show()

fper_rf, tper_rf, thresholds = roc_curve(test_y, predict_prob_rf)

print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_rf)*100))
#print('Accuracy --> ',accuracy_score(test_y,predict_rf))

print('Precision --> {:.4}%' .format(precision_score(test_y,predict_rf)*100))

print('Recall --> {:.4}%' .format(recall_score(test_y,predict_rf)*100))
##print('Recall --> ',recall_score(y_test,predict_rf))

print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_rf)*100))

print('Classification Report  --> \n',classification_report(test_y,predict_rf))

plot_roc_curve(fper_rf, tper_rf)
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_rf)))
##print(f'ROC AUC score: {roc_auc_score(test_y,predict_prob_rf)}')

endrf = time.time()
print('Tempo de processamento do modelo:', endrf-startrf)
print('\n')

print('========================')
print('TESTANDO O MODELO')
print('========================')
print('\n')

print("Amostra selecionada:\n", teste_x[50:51])
print("Resultado da amostra selecionada:\n", teste_y[50:51])

previsoesdoalgoritmoRF=rf.predict(teste_x[50:51])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoRF)

print("Amostra selecionada:\n", teste_x[13:14])
print("Resultado da amostra selecionada:\n", teste_y[13:14])

previsoesdoalgoritmoRF=rf.predict(teste_x[13:14])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoRF)

""" **XGBClassifier**"""

print('XGB CLASSIFIER')

#startxgbc = time.time()
#xgbc=XGBClassifier()
#xgbc=XGBClassifier(objective='binary:logistic',n_estimators=100000,max_depth=5,learning_rate=0.001,n_jobs=-1)
#xgbc=XGBClassifier(objective='binary:logistic',n_estimators=400000,max_depth=5,learning_rate=0.001,n_jobs=-1)
#xgbc=XGBClassifier(objective='binary:logistic',n_estimators=1000,max_depth=5,learning_rate=0.0001,n_jobs=-1)
#xgbc=XGBClassifier(eval_metric='error',learning_rate= 0.1)
#xgbc=XGBClassifier(n_estimators=1000,learning_rate=0.001,max_depth=20)
xgbc=XGBClassifier(n_estimators=10000,learning_rate=0.001,max_depth=20)
print('\n')

print('========================')
print('VALIDAÇÃO CRUZADA')
print('========================')
print('\n')

startxgbc_cv = time.time()
#SEED = 42
#np.random.seed(SEED)
for score in ["accuracy", "precision", "recall", "f1", "roc_auc"]:
  scr = score
  mscr = scr.upper()
  cv = StratifiedKFold(n_splits = 5, shuffle = True)
  results = cross_val_score(xgbc, train_x, train_y, cv = 5, scoring=score)
  cross(results,mscr)
endxgbc_cv = time.time()
print('Tempo de processamento do modelo para a validação cruzada:', endxgbc_cv-startxgbc_cv)
print('\n')

print('========================')
print('MODELO REAL')
print('========================')
print('\n')

startxgbc = time.time()
xgbc.fit(train_x,train_y)
predict_xgbc=xgbc.predict(test_x)
predict_prob_xgbc = xgbc.predict_proba(test_x)[:,1]

cm_xgbc = confusion_matrix(test_y, predict_xgbc)
heatmap = sns.heatmap(cm_xgbc, annot=True, fmt='d')
heatmap.set_title('Matriz de Confusão')
heatmap.set_xlabel('Classe Predita')
heatmap.set_ylabel('Classe Verdadeira')
plt.show()

#cm_xgbc = confusion_matrix(test_y, predict_xgbc, labels=xgbc.classes_)
#disp_xgbc = ConfusionMatrixDisplay(confusion_matrix=cm_xgbc,display_labels=xgbc.classes_)
#disp_xgbc.plot()
#plt.show()

fper_xgbc, tper_xgbc, thresholds = roc_curve(test_y, predict_prob_xgbc)

print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_xgbc)*100))
#print('Accuracy --> ',accuracy_score(test_y,predict_xgbc))

print('Precision --> {:.4}%' .format(precision_score(test_y,predict_xgbc)*100))

print('Recall --> {:.4}%' .format(recall_score(test_y,predict_xgbc)*100))
##print('Recall --> ',recall_score(y_test,predict_xgbc))

print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_xgbc)*100))
##print('F1 Score --> ',f1_score(test_y,predict_xgbc))

print('Classification Report  --> \n',classification_report(test_y,predict_xgbc))

plot_roc_curve(fper_xgbc, tper_xgbc)
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_xgbc)))
##print(f'ROC AUC score: {roc_auc_score(test_y,predict_prob_xgbc)}')

endxgbc = time.time()
print('Tempo de processamento do modelo:', endxgbc-startxgbc)
print('\n')

print('========================')
print('TESTANDO O MODELO')
print('========================')
print('\n')

print("Amostra selecionada:\n", teste_x[50:51])
print("Resultado da amostra selecionada:\n", teste_y[50:51])

previsoesdoalgoritmoXGBC=xgbc.predict(teste_x[50:51])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoXGBC)

print("Amostra selecionada:\n", teste_x[13:14])
print("Resultado da amostra selecionada:\n", teste_y[13:14])

previsoesdoalgoritmoXGBC=xgbc.predict(teste_x[13:14])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoXGBC)

"""**MLP**"""

print('MLP')

#startmlp = time.time()
#mlp = MLPClassifier()
#mlp = MLPClassifier(random_state=1)
mlp = MLPClassifier(learning_rate_init =0.001,max_iter=10000,hidden_layer_sizes=100)
print('\n')

print('========================')
print('VALIDAÇÃO CRUZADA')
print('========================')
print('\n')

startmlp_cv = time.time()
#SEED = 42
#np.random.seed(SEED)
for score in ["accuracy", "precision", "recall", "f1", "roc_auc"]:
  scr = score
  mscr = scr.upper()
  cv = StratifiedKFold(n_splits = 5, shuffle = True)
  results = cross_val_score(mlp, train_x, train_y, cv = 5, scoring=score)
  cross(results,mscr)
endmlp_cv = time.time()
print('Tempo de processamento do modelo para a validação cruzada:', endmlp_cv-startmlp_cv)
print('\n')


print('========================')
print('MODELO REAL')
print('========================')
print('\n')

startmlp = time.time()
mlp.fit(train_x,train_y)
predict_mlp=mlp.predict(test_x)
predict_prob_mlp = mlp.predict_proba(test_x)[:,1]

cm_mlp = confusion_matrix(test_y, predict_mlp)
heatmap = sns.heatmap(cm_mlp, annot=True, fmt='d')
heatmap.set_title('Matriz de Confusão')
heatmap.set_xlabel('Classe Predita')
heatmap.set_ylabel('Classe Verdadeira')
plt.show()

#cm_mlp = confusion_matrix(test_y, predict_mlp, labels=mlp.classes_)
#disp_mlp = ConfusionMatrixDisplay(confusion_matrix=cm_mlp,display_labels=mlp.classes_)
#disp_mlp.plot()
#plt.show()

fper_mlp, tper_mlp, thresholds = roc_curve(test_y, predict_prob_mlp)

print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_mlp)*100))

print('Precision --> {:.4}%' .format(precision_score(test_y,predict_mlp)*100))

print('Recall --> {:.4}%' .format(recall_score(test_y,predict_mlp)*100))

print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_mlp)*100))

print('Classification Report  --> \n',classification_report(test_y,predict_mlp))

plot_roc_curve(fper_mlp, tper_mlp)
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_mlp)))

endmlp = time.time()
print('Tempo de processamento do modelo:', endmlp-startmlp)
print('\n')

print('========================')
print('TESTANDO O MODELO')
print('========================')
print('\n')

print("Amostra selecionada:\n", teste_x[50:51])
print("Resultado da amostra selecionada:\n", teste_y[50:51])

previsoesdoalgoritmoMLP=mlp.predict(teste_x[50:51])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoMLP)

print("Amostra selecionada:\n", teste_x[13:14])
print("Resultado da amostra selecionada:\n", teste_y[13:14])

previsoesdoalgoritmoMLP=mlp.predict(teste_x[13:14])
print("Previsão do Algoritmo: \n", previsoesdoalgoritmoMLP)

"""No conjunto de dados balanceado, contamos com a precisão, mas aqui temos um conjunto de dados desequilibrado, por isso devemos considerar a pontuação de AUC. Para um bom classificador, seria ótimo ter uma boa pontuação de precisão e recall. De todos os modelos, o LGBMClassifier tem um ótimo resultado. Portanto, como modelo, estou selecionando XGBClassifier."""

fig, ax = plt.subplots(figsize = (20,10))
plt.plot(fper_dtc, tper_dtc, label='Decision Tree Classifier')
plt.plot(fper_knn, tper_knn, label='KNN')
plt.plot(fper_lor, tper_lor, label='Logistic Regression')
plt.plot(fper_gnb, tper_gnb, label='Naive Bayes')
plt.plot(fper_svc, tper_svc, label='SVM')
plt.plot(fper_cbc, tper_cbc, label='Cat Boost Classifier')
plt.plot(fper_lgbmc, tper_lgbmc, label='LGBMClassifier')
plt.plot(fper_rf, tper_rf, label='Ramdom Forest')
plt.plot(fper_xgbc, tper_xgbc, label='XGBClassifier')
plt.plot(fper_mlp, tper_mlp, label='MLP')

plt.plot([0, 1], [0, 1], color='green', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC - Receiver Operating Characteristic Curve', fontsize = 14)
plt.legend()
plt.show()

print('==================================================')
print('=============== METODOS CLASSICOS ================')
print('==================================================')
print('\n')
print('DECISION TREE')
print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_dtc)*100))
print('Precision --> {:.4}%' .format(precision_score(test_y,predict_dtc)*100))
print('Recall --> {:.4}%' .format(recall_score(test_y,predict_dtc)*100))
print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_dtc)*100))
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_dtc)))
print('Tempo de processamento do modelo:', enddtc-startdtc)
print('\n')
print('==================================================')
print('KNN')
print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_knn)*100))
print('Precision --> {:.4}%' .format(precision_score(test_y,predict_knn)*100))
print('Recall --> {:.4}%' .format(recall_score(test_y,predict_knn)*100))
print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_knn)*100))
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_knn)))
print('Tempo de processamento do modelo:', endknn-startknn)
print('\n')
print('==================================================')
print('LOGISTIC REGRESSION')
print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_lor)*100))
print('Precision --> {:.4}%' .format(precision_score(test_y,predict_lor)*100))
print('Recall --> {:.4}%' .format(recall_score(test_y,predict_lor)*100))
print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_lor)*100))
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_lor)))
print('Tempo de processamento do modelo:', endlor-startlor)
print('\n')
print('==================================================')
print('NAIVE BAYES')
print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_gnb)*100))
print('Precision --> {:.4}%' .format(precision_score(test_y,predict_gnb)*100))
print('Recall --> {:.4}%' .format(recall_score(test_y,predict_gnb)*100))
print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_gnb)*100))
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_gnb)))
print('Tempo de processamento do modelo:', endgnb-startgnb)
print('\n')
print('==================================================')
print('SVM')
print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_svc)*100))
print('Precision --> {:.4}%' .format(precision_score(test_y,predict_svc)*100))
print('Recall --> {:.4}%' .format(recall_score(test_y,predict_svc)*100))
print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_svc)*100))
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_svc)))
print('Tempo de processamento do modelo:', endsvc-startsvc)
print('\n')
print('=================================================')
print('=============== METODOS ENSEMBLE ================')
print('=================================================')
print('\n')
print('==================================================')
print('CAT BOOST CLASSIFIER')
print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_cbc)*100))
print('Precision --> {:.4}%' .format(precision_score(test_y,predict_cbc)*100))
print('Recall --> {:.4}%' .format(recall_score(test_y,predict_cbc)*100))
print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_cbc)*100))
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_cbc)))
print('Tempo de processamento do modelo:', endcbc-startcbc)
print('\n')
print('==================================================')
print('LGBM CLASSIFIER')
print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_lgbmc)*100))
print('Precision --> {:.4}%' .format(precision_score(test_y,predict_lgbmc)*100))
print('Recall --> {:.4}%' .format(recall_score(test_y,predict_lgbmc)*100))
print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_lgbmc)*100))
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_lgbmc)))
print('Tempo de processamento do modelo:', endlgbmc-startlgbmc)
print('\n')
print('==================================================')
print('RANDOM FOREST')
print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_rf)*100))
print('Precision --> {:.4}%' .format(precision_score(test_y,predict_rf)*100))
print('Recall --> {:.4}%' .format(recall_score(test_y,predict_rf)*100))
print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_rf)*100))
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_rf)))
print('Tempo de processamento do modelo:', endrf-startrf)
print('\n')
print('==================================================')
print('XGBOOST CLASSIFIER')
print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_xgbc)*100))
print('Precision --> {:.4}%' .format(precision_score(test_y,predict_xgbc)*100))
print('Recall --> {:.4}%' .format(recall_score(test_y,predict_xgbc)*100))
print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_xgbc)*100))
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_xgbc)))
print('Tempo de processamento do modelo:', endxgbc-startxgbc)
print('\n')
print('=================================================')
print('=============== REDES NEURAIS ===================')
print('=================================================')
print('\n')
print('==================================================')
print('MLP')
print('Accuracy --> {:.4}%' .format(accuracy_score(test_y,predict_mlp)*100))
print('Precision --> {:.4}%' .format(precision_score(test_y,predict_mlp)*100))
print('Recall --> {:.4}%' .format(recall_score(test_y,predict_mlp)*100))
print('F1 Score --> {:.4}%' .format(f1_score(test_y,predict_mlp)*100))
print('ROC AUC score --> {:.4}' .format(roc_auc_score(test_y,predict_prob_mlp)))
print('Tempo de processamento do modelo:', endmlp-startmlp)
print('\n')
print('=================================================')

"""# **Fechamento**

Therefore, in this project, we examined some of the factors that may result in stroke events. Age showed the highest correlation, followed by hypertension, heart disease, average glucose level, and marital status.

The XGB Classifier was a method that demonstrated good performance.
"""
